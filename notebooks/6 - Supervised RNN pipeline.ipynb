{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "organic-recycling",
   "metadata": {},
   "source": [
    "# Supervised RNN pipeline with Tensorflow\n",
    "\n",
    "This notebook trains a supervised RNN model via Tensorflow, considering the case of using a window of data to predict the activity within the window.\n",
    "\n",
    "Specifically,\n",
    "* We use the raw sensor data, not the feature data\n",
    "* Use `tensorflow.keras` to set up and train the model\n",
    "* A single-hidden-LSTM-layer forecasting model is trained (multi-classification)\n",
    "\n",
    "We finally test the model on the test data set, as defined by the authors.\n",
    "\n",
    "Note: some improvements could be made with respect to the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "literary-country",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "light-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from src.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-eight",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "Load the raw data and then prepare the train / test objects.\n",
    "\n",
    "Note that\n",
    "1. We need to construct the windows of the 9 sensor data series into shapes of $(128, 9)$\n",
    "1. We need to format the integer activity labels as one-hot-encoded vectors like in the DNN pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-iceland",
   "metadata": {},
   "source": [
    "The data is loaded here as a normally-structured time series data set, like in the data description. We do this because we want to scale the dataset before putting into `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coordinate-material",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(941056, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df = load_raw_data() \\\n",
    "    .sort_values(['subject_id', 'time_exp']) \\\n",
    "    .reset_index(drop=True)\n",
    "raw_train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-scottish",
   "metadata": {},
   "source": [
    "Now create the training array without subject, activity labels, etc. Also, create the one-hot-encoded label array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "specialized-rachel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((941056, 9), (7352, 6))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = raw_train_df.drop(['subject_id', 'time_exp', 'time_window_s', 'time_counter', 'activity_id'], axis=1)\n",
    "labels_train = raw_train_df.loc[:, ['subject_id', 'time_window_s', 'activity_id']].drop_duplicates().activity_id\n",
    "y_train = keras.utils.to_categorical(labels_train - 1)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-kennedy",
   "metadata": {},
   "source": [
    "Repeat the above process for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "referenced-electron",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377216, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_df = load_raw_data('test') \\\n",
    "    .sort_values(['subject_id', 'time_exp', 'time_counter']) \\\n",
    "    .reset_index(drop=True)\n",
    "raw_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "suffering-boulder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((377216, 9), (2947, 6))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = raw_test_df.drop(['subject_id', 'time_exp', 'time_window_s', 'time_counter', 'activity_id'], axis=1)\n",
    "labels_test = raw_test_df.loc[:, ['subject_id', 'time_window_s', 'activity_id']].drop_duplicates().activity_id\n",
    "y_test = keras.utils.to_categorical(labels_test - 1)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-frame",
   "metadata": {},
   "source": [
    "We now scale the data like normal. This won't be part of the pipeline in order to keep the `keras` model simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rural-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "national-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window_qt, test_window_qt = y_train.shape[0], y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mental-democracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 128, 9), (2947, 128, 9))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_input = X_train.reshape((train_window_qt, 128, 9))\n",
    "X_test_input = X_test.reshape((test_window_qt, 128, 9))\n",
    "X_train_input.shape, X_test_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-survival",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-mexican",
   "metadata": {},
   "source": [
    "### Prepare the model\n",
    "\n",
    "We create a single hidden LSTM layer with 3 nodes. Using the `Sequential` API, we create the model object and `.add` layers to it. The last layer must be congruent with the model task: a 6-category prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "noted-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(3, input_shape=(128, 9)))\n",
    "model.add(keras.layers.Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-exemption",
   "metadata": {},
   "source": [
    "We need to add a loss function, optimizer, and metrics for training.\n",
    "* The `categorical_crossentropy` is a good choice for multi-category classification\n",
    "* The `rmsprop` optimizer performs well here\n",
    "* `accuracy` is a common metric to choose; it must get the label exactly right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bored-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-reservation",
   "metadata": {},
   "source": [
    "We can summarize the model for our understanding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "embedded-classics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 3)                 156       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 24        \n",
      "=================================================================\n",
      "Total params: 180\n",
      "Trainable params: 180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-location",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "In this example, we fit the model with a single validation data set. This is actually common in deep learning problems, since the datasets are so large that cross-validation is often not necessary.\n",
    "\n",
    "Some notes:\n",
    "* We choose the batch size as 32 since it's on par with the way the data is recorded\n",
    "* Using 3 epochs is common, but could be increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ignored-medicare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "230/230 [==============================] - 6s 23ms/step - loss: 1.7070 - accuracy: 0.2119 - val_loss: 1.5745 - val_accuracy: 0.3553\n",
      "Epoch 2/3\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 1.4953 - accuracy: 0.4010 - val_loss: 1.4102 - val_accuracy: 0.4320\n",
      "Epoch 3/3\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 1.3270 - accuracy: 0.4895 - val_loss: 1.2827 - val_accuracy: 0.5083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f02e4611040>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_input, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=3,\n",
    "          validation_data=(X_test_input, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-cedar",
   "metadata": {},
   "source": [
    "The `keras` fitting process already prints out the accuracy, but for illustration we can compute it like we did in the other notebooks, only we need to translate the one-hot-encoded vector back to the integer label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "australian-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat = model.predict(X_train_input)\n",
    "y_train_hat = np.array([y.argmax() + 1 for y in y_train_hat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "nonprofit-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "controlling-arrival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5447497279651795"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train_hat, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-curtis",
   "metadata": {},
   "source": [
    "### Evaluate on the test data\n",
    "\n",
    "We evaluate the model on the test data that was defined by the authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "numerous-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = model.predict(X_test_input)\n",
    "y_test_hat = np.array([y.argmax() + 1 for y in y_test_hat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "verified-mother",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5083135391923991"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_hat, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "limited-leave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.40      0.13        97\n",
      "           2       0.05      0.32      0.08        73\n",
      "           3       0.37      0.35      0.36       449\n",
      "           4       0.76      0.49      0.59       763\n",
      "           5       0.76      0.47      0.58       856\n",
      "           6       0.94      0.72      0.81       709\n",
      "\n",
      "    accuracy                           0.51      2947\n",
      "   macro avg       0.49      0.46      0.43      2947\n",
      "weighted avg       0.70      0.51      0.58      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_hat, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-florist",
   "metadata": {},
   "source": [
    "When we cross-tabulate the actual labels with the classified ones, we don't see great agreement, but many improvements could be made. \n",
    "\n",
    "Here we will want to validate if the errors made are acceptable. For example, errors for walking downstairs are either walking or walking upstairs. It may be important to continue tuning parameters such that this activity is never (or less commonly) misclassified as walking upstairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "jewish-anchor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classified</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "      <td>135</td>\n",
       "      <td>133</td>\n",
       "      <td>128</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>144</td>\n",
       "      <td>79</td>\n",
       "      <td>135</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>155</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>372</td>\n",
       "      <td>98</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>118</td>\n",
       "      <td>402</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classified   1   2    3    4    5    6\n",
       "True                                  \n",
       "1           39  23  135  133  128   38\n",
       "2           33  23  144   79  135   57\n",
       "3           21  25  155   61   66   92\n",
       "4            1   2    5  372   98   13\n",
       "5            3   0    7  118  402    2\n",
       "6            0   0    3    0   27  507"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(labels_test,\n",
    "            y_test_hat,\n",
    "            rownames=['True'],\n",
    "            colnames=['Classified'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-centre",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
