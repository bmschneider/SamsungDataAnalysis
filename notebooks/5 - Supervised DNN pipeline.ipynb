{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "continent-perception",
   "metadata": {},
   "source": [
    "# Supervised DNN pipeline with Tensorflow\n",
    "\n",
    "This notebook trains a supervised model via Tensorflow\n",
    "\n",
    "Specifically,\n",
    "* Use `tensorflow.keras` to set up and train the model\n",
    "* A single-hidden-layer cross-sectional model is trained (multi-classification)\n",
    "\n",
    "We finally test the model on the test data set, as defined by the authors.\n",
    "\n",
    "Note: some improvements could be made with respect to the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "consolidated-virginia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "empirical-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "asian-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-butterfly",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "Load the feature data and then prepare the train / test objects.\n",
    "\n",
    "Note that `keras` is different from `sklearn` in that we need to format the integer activity labels as one-hot-encoded vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "governing-theology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 564)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities = load_activity_names(); activities\n",
    "features_df = load_feature_data() \\\n",
    "    .sort_values(['subject_id', 'time_exp']) \\\n",
    "    .reset_index(drop=True)\n",
    "features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-steal",
   "metadata": {},
   "source": [
    "We only input the data features into the model, so we need to skip subject, time, and activity labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "genetic-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = features_df.drop(['subject_id', 'time_exp', 'activity_id'], axis=1)\n",
    "y_train = keras.utils.to_categorical(features_df.activity_id - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "united-license",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947, 564)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test_df = load_feature_data('test') \\\n",
    "    .sort_values(['subject_id', 'time_exp']) \\\n",
    "    .reset_index(drop=True)\n",
    "X_test = features_test_df.drop(['subject_id', 'time_exp', 'activity_id'], axis=1)\n",
    "y_test = keras.utils.to_categorical(features_test_df.activity_id - 1)\n",
    "features_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-outdoors",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-turning",
   "metadata": {},
   "source": [
    "### Prepare the model\n",
    "\n",
    "We create a single hidden layer DNN with 100 nodes. Using the `Sequential` API, we create the model object and `.add` layers to it. The last layer must be congruent with the model task: a 6-category prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "charged-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(100))\n",
    "model.add(keras.layers.Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-reference",
   "metadata": {},
   "source": [
    "We need to add a loss function, optimizer, and metrics for training.\n",
    "* The `categorical_crossentropy` is a good choice for multi-category classification\n",
    "* The `Adam` optimizer generally performs well\n",
    "* `accuracy` is a common metric to choose; it must get the label exactly right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "possible-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-devon",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "In this example, we fit the model with a single validation data set. This is actually common in deep learning problems, since the datasets are so large that cross-validation is often not necessary.\n",
    "\n",
    "Some notes:\n",
    "* We choose the batch size as 128 since it's on par with the way the data is recorded\n",
    "* Using 3 epochs is common, but could be increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "written-front",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "58/58 [==============================] - 1s 6ms/step - loss: 1.0264 - accuracy: 0.5911 - val_loss: 0.3560 - val_accuracy: 0.8748\n",
      "Epoch 2/3\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.9117 - val_loss: 0.2670 - val_accuracy: 0.9019\n",
      "Epoch 3/3\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.9319 - val_loss: 0.2101 - val_accuracy: 0.9338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f669b6b5b20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=3,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-majority",
   "metadata": {},
   "source": [
    "We can summarize the model for our understanding. Note there is a large number of parameters to fit. We can see this, noting that a 561-length vector's elements are being multiplied 100 times each in order to be summed into the 100 nodes. There is also the 100-element bias vector. That adds up to 56200. Similarly, 100-hidden-nodes are multiplied 6 times each to arrive at the 6 output nodes, which each have a bias parameter. That adds up to 606."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "imported-savings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               56200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 56,806\n",
      "Trainable params: 56,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-payment",
   "metadata": {},
   "source": [
    "The full specification of the model can be obtained as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "polyphonic-metallic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 561),\n",
       "    'dtype': 'float64',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'dense_input'}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 100,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 6,\n",
       "    'activation': 'softmax',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-scale",
   "metadata": {},
   "source": [
    "The `keras` fitting process already prints out the accuracy, but for illustration we can compute it like we did in the other notebooks, only we need to translate the one-hot-encoded vector back to the integer label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cathedral-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat = model.predict(X_train)\n",
    "y_train_hat = np.array([y.argmax() + 1 for y in y_train_hat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "annual-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "distant-gazette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9578346028291621"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train_hat, features_df.activity_id.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-identification",
   "metadata": {},
   "source": [
    "### Evaluate on the test data\n",
    "\n",
    "We evaluate the model on the test data that was defined by the authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "higher-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = model.predict(X_test)\n",
    "y_test_hat = np.array([y.argmax() + 1 for y in y_test_hat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "accompanied-visibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9338310145911096"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_hat, features_test_df.activity_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "rapid-durham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.91      0.95       538\n",
      "           2       0.89      0.95      0.92       442\n",
      "           3       0.92      0.95      0.93       410\n",
      "           4       0.86      0.92      0.89       460\n",
      "           5       0.93      0.88      0.91       563\n",
      "           6       0.99      1.00      1.00       534\n",
      "\n",
      "    accuracy                           0.93      2947\n",
      "   macro avg       0.93      0.94      0.93      2947\n",
      "weighted avg       0.94      0.93      0.93      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_hat, features_test_df.activity_id.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-seeker",
   "metadata": {},
   "source": [
    "When we cross-tabulate the actual labels with the classified ones, we see a pretty diagonal matrix. \n",
    "\n",
    "Here we will want to validate if the errors made are acceptable. For example, errors for walking downstairs are either walking or walking upstairs. It may be important to continue tuning parameters such that this activity is never (or less commonly) misclassified as walking upstairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "amazing-summer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classified</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>420</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>388</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>424</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classified    1    2    3    4    5    6\n",
       "True                                    \n",
       "1           491    0    5    0    0    0\n",
       "2            34  420   17    0    0    0\n",
       "3            13   19  388    0    0    0\n",
       "4             0    3    0  424   63    1\n",
       "5             0    0    0   36  496    0\n",
       "6             0    0    0    0    4  533"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(features_test_df.activity_id.values,\n",
    "            y_test_hat,\n",
    "            rownames=['True'],\n",
    "            colnames=['Classified'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-married",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
